# Problem 2
# (text book 4.2) 
## part b

n<- c(379,299,222,145,109,95,73,59,45,30,24,12,4,2,0,1,1)
N<- 1500

# theta=c(alpha,beta,mu,lambda)
pai=function(i,theta)
{
  indicator=ifelse(i==0,1,0)
  temp=theta[1]*indicator+theta[2]*theta[3]^i*exp(-theta[3])+(1-theta[1]-theta[2])*theta[4]^i*exp(-theta[4])
  return(temp)
}

z=function(i,theta)
{ 
  indicator<- ifelse(i==0,1,0)
  temp=theta[1]*indicator/pai(i,theta)
  return(temp)
}

t=function(i,theta)
{
  temp=theta[2]*theta[3]^i*exp(-theta[3])/pai(i,theta)
  return(temp)
}

p=function(i,theta)
{
  temp=(1-theta[1]-theta[2])*theta[4]^i*exp(-theta[4])/pai(i,theta)
  return(temp)
}



# since we have also deducted the update formula for theta
# we can use relative convergence criterian
# r(t)=||theta(t)-theta(t-1)||/||theta(t-1)||<e, where e is a very small number

EM=function(theta,e)
{
r<- c()
r[1]<- 1
k<- 1
j<- 1
#theta.matrix<- matrix(0,4,100)
#theta.matrix[,1]<-theta

while (r[k]>e)
{
# theta0 stands for the value of theta before this iteration
theta0<- theta
# the updated formula for theta is:
theta[1]<- n[1]*z(0,theta)/N

# theta[2]
temp1<- c()
for(i in 0:16)
{
temp1[i+1]<- n[i+1]*t(i,theta)
}
theta[2]<- sum(temp1)/N
  
# theta[3]
temp2<- c()
temp3<- c()
for (i in 0:16)
{
  temp2[i+1]<- i*n[i+1]*t(i,theta)
  temp3[i+1]<- n[i+1]*t(i,theta)
}
theta[3]<- sum(temp2)/sum(temp3)

# theta[4]
temp4<- c()
temp5<- c()
for (i in 0:16)
{
  temp4[i+1]<- i*n[i+1]*p(i,theta)
  temp5[i+1]<- n[i+1]*p(i,theta)
}
theta[4]<- sum(temp4)/sum(temp5)

# r
k<- k+1
r[k]<- sqrt(sum((theta-theta0)^2)/sum(theta0^2))
#j<- j+1
#theta.matrix[,j]<- theta

}
return(list(theta=theta,r=r))
}

# test 
e<- 10^-5
# try the first starting value of theta
theta<- c(0.3,0.4,1,4)
myem1<- EM(theta,e)
myem$theta
# [1] 0.1221136 0.5625404 1.4671616 5.9385173

# try the second starting value of theta
theta<- c(0.5,0.1,2,10)
myem2<- EM(theta,e)
myem2$theta
# [1] 0.1222192 0.5625435 1.4677916 5.9392652

# try the third starting value of theta
theta<- c(0.6,0.1,10,40)
myem3<- EM(theta,e)
myem3$theta
# [1] 0.1222152 0.5625434 1.4677679 5.9392371

# the the fourth starting value of theta
theta<- c(0.5,0.3,4,5)
myem4<- EM(theta,e)
myem4$theta
# [1] 0.1222160 0.5625434 1.4677723 5.9392423

# As we can see, theta finally converged to the same value under different starting values
# So I think my EM algorithm is correct



# Problem 3
## part 1
markov.simu=function(rho,T)
{
  # the transition matrix p is:
  p<- matrix(c(1-3*rho,rho,2*rho,rho,1-5*rho,4*rho,2*rho,4*rho,1-6*rho),nrow=3)
  # the size of state space is 3
  
  # path is a vector of state at each time, from 0 to T
  path<- c()
  # the state at time 0 is:
  path[1]<- 1
  
  for (i in 2:(T+1))
  { # path[i] is the state at time i-1
    path[i]<- sample(1:3,1,prob=p[path[i-1],])
    
  }
  
  return(list(trans=p,path=path))
}

# since each entry of the transition matrix
# should be larger than 0
# we demand that 1-6*rho>0 and rho>0
# i.e. 0<rho<1/6

# test
rho<- 1/8
T<- 20
markov.simu(rho,T)
#$trans
#[,1]  [,2] [,3]
#[1,] 0.625 0.125 0.25
#[2,] 0.125 0.375 0.50
#[3,] 0.250 0.500 0.25

#$path
#[1] 1 3 2 3 2 2 3 2 3 3 3 1 1 3 1 1 1 1 1 1 1

#$prob
#[1] 0.250 0.500 0.500 0.500 0.375 0.500 0.500 0.500 0.250 0.250 0.250 0.625 0.250 0.250
#[15] 0.625 0.625 0.625 0.625 0.625 0.625




## part b

# first to write a function to generate transition matrix
tran=function(rho)
{
  matrix(c(1-3*rho,rho,2*rho,rho,1-5*rho,4*rho,2*rho,4*rho,1-6*rho),nrow=3)
}

### i eigen vector method
# to find s statisfies sp=s. s ia a stationary matrix(distribution)

# when rho=0.1

p1<- tran(0.1)
#p1
#[,1]  [,2]  [,3]
#[1,]  0.7  0.1  0.2
#[2,]  0.1  0.5  0.4
#[3,]  0.2  0.4  0.4
eigen(p1)
#$values
#1] 1.00000000 0.56457513 0.03542487

#$vectors
#[,1]       [,2]       [,3]
#[1,] -0.5773503  0.8051731 -0.1355099
#[2,] -0.5773503 -0.5199416 -0.6295454
#[3,] -0.5773503 -0.2852315  0.7650553

# as we can see, the eigenvector corresponding to eigenvalue 1 is (-0.5773503,-0.5773503,-0.5773503)
ptm1<- proc.time()
s1<- eigen(p1)$vectors[,1]
# normalize the eigen vector
s1<- s1/sum(s1)
#[1] 0.3333333 0.3333333 0.3333333
# so the stationary distribution for rho=0.1 is s1=(0.3333333,0.3333333,0.3333333)
proc.time()-ptm1
# the time is
# user  system elapsed
# 0 0 0


# when rho=0.01

p2<-tran(0.01)
p2
#[,1] [,2] [,3]
#[1,] 0.97 0.01 0.02
#[2,] 0.01 0.95 0.04
#[3,] 0.02 0.04 0.94
eigen(p2)
#$values
#[1] 1.0000000 0.9564575 0.9035425

#$vectors
#[,1]       [,2]       [,3]
#[1,] -0.5773503  0.8051731 -0.1355099
#[2,] -0.5773503 -0.5199416 -0.6295454
#[3,] -0.5773503 -0.2852315  0.7650553

# as we can see, the eigenvector corresponding to eigenvalue 1 is (-0.5773503,-0.5773503,-0.5773503)
ptm2<- proc.time()
s2<- eigen(p2)$vectors[,1]
# normalize the eigen vector
s2<- s2/sum(s2)
#[1] 0.3333333 0.3333333 0.3333333
# so the stationary distribution for rho=0.01 is s2=(0.3333333,0.3333333,0.3333333)
proc.time()-ptm2
# the time is
# 0 0 0 

# when rho=0.001

p3<- tran(0.001)
p3
#[,1]  [,2]  [,3]
#[1,] 0.997 0.001 0.002
#[2,] 0.001 0.995 0.004
#[3,] 0.002 0.004 0.994
eigen(p3)
#$values
#[1] 1.0000000 0.9956458 0.9903542

#$vectors
#[,1]       [,2]       [,3]
#[1,] -0.5773503  0.8051731 -0.1355099
#[2,] -0.5773503 -0.5199416 -0.6295454
#[3,] -0.5773503 -0.2852315  0.7650553

# as we can see, the eigenvector corresponding to eigenvalue 1 is (-0.5773503,-0.5773503,-0.5773503)
ptm3<- proc.time()
s3<- eigen(p3)$vectors[,1]
# normalize the eigen vector
s3<- s3/sum(s3)
#[1] 0.3333333 0.3333333 0.3333333
# so the stationary distribution for rho=0.001 is s3=(0.3333333,0.3333333,0.3333333)
proc.time()-ptm3
# the time is 
# 0 0 0

# In this method, rho=0.001, rho=0.1 and 0.01 took the same time
# I don't see a clear trend of process time change due to the change in values of rho
# I guess the reason is: the method is basicly computing the eigenvectors, which is
#  hardly time-comusming for low dimension matrices. So the difference is not obvious


### ii Monte Carlo Method

set.seed(123)
# suppose u0 is the initial state distribution
# we know that it will finally converge to the stationary state distribution
# randomly sample u0
# notice that all the entries of u0 should be larger than 0 sum up to 1

mt=function(rho,T)
{
  pi<- c()
  mc<- markov.simu(rho,T)$path
  pi[1]<- sum(mc==1)/T
  pi[2]<- sum(mc==2)/T
  pi[3]<- sum(mc==3)/T
  return(pi)
  
}

mt(0.1,100000)




### iii limiting matrix method

highpower.p=function(rho,e)
{
  p<- tran(rho)  
  r1<- p[,1]
  r2<- p[,2]
  r3<- p[,3]
  t<- 1
  
  while (abs(r1-r2)>e || abs(r2-r3)>3 ||abs(r1-r3)>e)
  {
    p<- p%*%p
    r1<- p[,1]
    r2<- p[,2]
    r3<- p[,3]
    t<- t+1
  }
  return(list(p=p,staionary.dist=p[1,],iterations=t))
}

e<- 10^-5

ptm1<- proc.time()
# when rho=0.1
highpower.p(0.1,e)

#$p
#[,1]      [,2]      [,3]
#[1,] 0.3333333 0.3333333 0.3333333
#[2,] 0.3333333 0.3333333 0.3333333
#[3,] 0.3333333 0.3333333 0.3333333

#$staionary.dist
#[1] 0.3333333 0.3333333 0.3333333

#$iterations
#[1] 6

proc.time()-ptm1
# the time is
# 0  0  0

ptm2<- proc.time()
# when rho=0.01
highpower.p(0.01,e)
#$p
#[,1]      [,2]      [,3]
#[1,] 0.3333333 0.3333333 0.3333333
#[2,] 0.3333333 0.3333333 0.3333333
#[3,] 0.3333333 0.3333333 0.3333333

#$staionary.dist
#[1] 0.3333333 0.3333333 0.3333333

#$iterations
#[1] 10
proc.time()-ptm2
# the time is
# 0 0 0

ptm3<- proc.time()
# when rho=0.001
highpower.p(0.001,e)
#$p
#[,1]      [,2]      [,3]
#[1,] 0.3333333 0.3333333 0.3333333
#[2,] 0.3333333 0.3333333 0.3333333
#[3,] 0.3333333 0.3333333 0.3333333

#$staionary.dist
#[1] 0.3333333 0.3333333 0.3333333

#$iterations
#[1] 13

proc.time()-ptm3
# the time is 
# 0 0 0

# In this method, rho=0.1, 0.01, and 0.001 takes the same time to converge


### iiii

# from the above three methods,I didn't see an obvious trend of how the converge time
# changes due to the change in values of rho (maybe because the matrix is too simple
# and the computation is too simple???)

# however, theoretically, the converge rate is related with a speed of ¦Ë2/¦Ë1 exponentially
# the smaller the ¦Ë2/¦Ë1, the faster the converge speed
# (suppose ¦Ë1, ¦Ë2 and ¦Ë3 are the eigenvalues of P, and |¦Ë1|=1>|¦Ë2|>|¦Ë3|)

# notice that:
# when rho=0.1, e-value= (1.00000000,0.56457513,0.03542487), and |lambda2|/|lambda1|= 0.56457513
# when rho=0.01, e-value= (1.0000000,0.9564575,0.9035425), and |lambda2|/|lambda1|= 0.9564575
# when rho=0.001, e-value= (1.0000000,0.9956458,0.9903542), and |lambda2|/|lambda1|= 0.9956458
# 0.9956458>0.9564575>0.56457513
# therefore, theoretically, the rho=0.1 should have the fastest speed,
# and rho=0.001 should have the slowest speed
# the proof is as follow:
